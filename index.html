<!DOCTYPE html>
<html lang="en">
<head>
  <title>Image classification using MobileNet and p5.js</title>
  <meta charset="utf-8" />
  <link rel="icon" href="images/favicon.png" type="image/x-icon">

  <link rel="stylesheet" type="text/css" href="style.css">

  <script src="https://cdn.jsdelivr.net/npm/p5@1.11.5/lib/p5.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.11.3/addons/p5.sound.min.js"></script>
  <script src="https://unpkg.com/ml5@1/dist/ml5.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

   <style>
    h1, h2 {
      color: #1976d2;
    }
    #loading, #p5_loading {
      font-size: 18px;
      color: #666;
      text-align: center;
      margin-top: 100px;
    }
    
    #outer-container,  #p5_loading { {
      display: none; /* WICHTIG: Verstecken bis alles fertig */
    }
  </style> 
</head>

<body>

  <div id="loading">Loading images and classification results...</div>

  <div id="outer-container">
     <h1>Image Classification Web App using MobileNet and ml5.js</h1>

  <h2>Overview</h2>
  <p>
    This project implements an interactive web application that performs real-time 
    image classification using the MobileNet model through the ml5.js library. Users 
    can observe the classification of a predefined set of images or upload their own images through a modern user interface.
  </p>

    <table id="container" style="width: 100%; border-collapse: collapse; margin-right:25px;">
      <tbody>
        <!-- Dynamisch befÃ¼llte Bilder und Charts -->
      </tbody>
    </table>

    <section id="project-documentation">

 
  <h2>1) Technical Documentation</h2>

  <h3>Frameworks and Libraries Used:</h3>
  <ul>
    <li><strong><a href="https://p5js.org/" target="_blank">p5.js</a></strong>: Used for basic image handling, DOM manipulation, and preload functionality.</li>
    <li><strong><a href="https://ml5js.org/" target="_blank">ml5.js</a></strong>: Simplified machine learning library built on top of TensorFlow.js, used for loading the pretrained MobileNet model and performing image classification.</li>
    <li><strong><a href="https://www.chartjs.org/" target="_blank">Chart.js</a></strong>: Used to visualize classification results as bar charts, showing the confidence levels of the top three predictions.</li>
    <li><strong><a href="https://docs.github.com/en/pages" target="_blank">GitHub Pages</a></strong>: Hosting platform for static sites, used to make the application publicly accessible.</li>
  </ul>

  <h3>Technical Specifications:</h3>
  <ul>
    <li>The application dynamically generates a structured table layout, displaying images and corresponding classification charts side-by-side.</li>
    <li>Drag & Drop and traditional file upload mechanisms are supported for user-uploaded images, seamlessly integrated into the same layout structure as the static images.</li>
    <li>Uploaded images overwrite previous uploads, maintaining a clean and minimal interface without duplication.</li>
    <li>All images (static and uploaded) are presented uniformly (300x300px) to ensure a consistent user experience and visual clarity.</li>
    <li>Validation ensures only JPG and PNG files under 5MB can be uploaded, with visible alerts if validation fails.</li>
    <li>The app is fully responsive and optimized for different screen sizes.</li>
  </ul>

  <h2>2) Subject-Specific Documentation</h2>

  <h3>Implementation of Logic and Key Elements:</h3>
  <ul>
    <li>
      The solution classifies a predefined set of static images using a pretrained MobileNet model from ml5.js, dynamically displaying the results in a structured and responsive table layout.
    </li>
    <li>
      Image classification is automatically triggered in the <code>setup()</code> function after preloading images. Each image and its corresponding chart are appended as a new table row, maintaining a clear and consistent structure.
    </li>
    <li>
      Labels under each image provide additional descriptive context. Classification results are visualized using bar charts that indicate the top three predictions and their respective confidence percentages.
    </li>
    <li>
      A dedicated upload section allows users to classify their own images, ensuring visual and interactive consistency with the predefined examples.
    </li>
    <li>
      Visual design follows Google's Material Design guidelines: primary and accent colors, rounded shapes, consistent elevation (shadows), and responsive layouts are used to enhance clarity and usability.
    </li>
    <li>
      Interaction design is guided by the ISO 9241-110 Human-Computer Interaction principles, particularly emphasizing:
      <ul>
        <li><strong>Suitability for the task:</strong> Simple, direct workflows for image upload and classification.</li>
        <li><strong>Self-descriptiveness:</strong> Clear labels and immediate feedback after actions.</li>
        <li><strong>Error tolerance:</strong> Validation for supported formats and file sizes with user-friendly error messages.</li>
        <li><strong>Feedback and help:</strong> Visible hints about supported file types and immediate success notifications after classification.</li>
      </ul>
    </li>
    <li>
      Testing revealed that familiar, high-contrast objects were classified accurately, whereas abstract or complex scenes, such as mosaics or certain dog breeds, led to reduced accuracy.
    </li>
    <li>
      Sources and references include official documentation from <strong>ml5.js</strong>, <strong>p5.js</strong>, and <strong>Chart.js</strong>, along with design principles from <strong>Google's Material Design Guidelines</strong>.
    </li>
  </ul>

  <h2>3) Observations and Discussion</h2>

  <p>
    The pretrained model accurately classified common everyday objects, landscapes, and typical animal species in most cases. High-quality input images with good contrast and clear object depiction greatly improved classification performance.
    Interestingly, even partial views, such as a fragment of a tandem bicycle, yielded correct results, despite being difficult for the human eye.
    However, classification accuracy declined with abstract, artistic representations or when images contained multiple objects or classes that visually resemble each other.
    For instance, the Laika dog breed was often misclassified due to its similarity to other dogs or even wolves. Additionally, the model struggled with landmark identification, such as the Eiffel Tower, especially in artistic formats like mosaics.
    Overall, the project demonstrates both the capabilities and the limitations of using pretrained machine learning models for real-world image classification.
  </p>

</section>

  </div>

  <!-- Ihr Sketch -->
  <script src="sketch.js"></script>

</body>
</html>
